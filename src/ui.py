import os
import streamlit as st
import shutil
from rag_pipeline import load_and_process_documents, create_vector_store, build_rag_chain

# Personaliza el estilo con CSS (opcional)
st.markdown(
    """
    <style>
    body {
        background-color: #F2F2F2;
    }
    .header {
        text-align: center;
        color: #4B0082;
    }
    .instructions {
        background-color: #4B0082;  /* Fondo oscuro */
        color: white;             /* Texto blanco */
        padding: 10px;
        border-radius: 5px;
        margin-bottom: 20px;
    }
    </style>
    """,
    unsafe_allow_html=True,
)
#No saleee!!!!
# T√≠tulo principal con emoji
st.markdown("<h1 class='header'>ü§ñ Chatbot RAG con LangGraph</h1>", unsafe_allow_html=True)

# Instrucciones al usuario
st.markdown(
    """
    <div class="instructions">
    <h3>üìö Instrucciones</h3>
    <ul>
      <li>Sube uno o varios archivos PDF. ¬°S√≠, funciona con m√∫ltiples PDFs para un an√°lisis conjunto!</li>
      <li>Presiona el bot√≥n <b>"Entrenar modelo"</b> para procesar y almacenar los documentos.</li>
      <li>Una vez entrenado, ingresa tu pregunta en el campo correspondiente y presiona <b>"Consultar"</b> para obtener la respuesta.</li>
    </ul>
    </div>
    """,
    unsafe_allow_html=True,
)

# Definir la ruta donde se guardar√°n los documentos
docs_path = "data/documents/"

# Esto debe elliminar la carpeta y su contenido si existe (para evitar archivos anteriores)
if os.path.exists(docs_path):
    shutil.rmtree(docs_path)
os.makedirs(docs_path, exist_ok=True)

# Subida de archivos PDF con mensaje
uploaded_files = st.file_uploader(
    "üìÑ Sube tus archivos PDF",
    accept_multiple_files=True,
    type=["pdf"],
    key="unique_pdf_uploader"
)
if uploaded_files:
    for uploaded_file in uploaded_files:
        file_path = os.path.join(docs_path, uploaded_file.name)
        with open(file_path, "wb") as f:
            f.write(uploaded_file.read())
    st.success("‚úÖ Archivos subidos correctamente.")

# Bot√≥n para entrenar el modelo
if st.button("Entrenar modelo", key="train_button"):
    with st.spinner("üöÄ Procesando documentos y entrenando el modelo..."):
        texts = load_and_process_documents()
        st.write("DEBUG: N√∫mero de fragmentos extra√≠dos:", len(texts))
        vector_db = create_vector_store(texts)
        st.write("DEBUG: Base vectorial:", vector_db)
        pipeline, _ = build_rag_chain(vector_db)
        st.session_state["rag_chain"] = pipeline
    st.success("üéâ Modelo entrenado con √©xito. Ahora puedes hacer preguntas.")

# Campo de entrada para la consulta
query = st.text_input("‚ùì Haz una pregunta sobre los documentos:", key="query_input")

# Bot√≥n para consultar
if st.button("Consultar", key="consult_button"):
    if "rag_chain" in st.session_state and query.strip():
        with st.spinner("üîç Consultando..."):
            result_state = st.session_state["rag_chain"]({"query": query})
            if result_state and isinstance(result_state, dict) and "response" in result_state:
                st.markdown("**Respuesta:**")
                st.write(result_state["response"])
            else:
                st.warning(f"‚ö†Ô∏è El objeto `result_state` no es v√°lido: {result_state}")
    else:
        st.warning("‚ö†Ô∏è No hay cadena RAG entrenada o la pregunta est√° vac√≠a.")
